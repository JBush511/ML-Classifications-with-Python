#Now, it is your turn, use the training set to build an accurate model. 
Then use the test set to report the accuracy of the model You should use the following algorithm:

K Nearest Neighbor(KNN)
Decision Tree
Support Vector Machine
Logistic Regression
__ Notice:__

You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.
You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.
You should include the code of the algorithm in the following cells.#
##

#K Nearest Neighbor(KNN)
#Notice: You should find the best k to build the model with the best accuracy.
#warning: You should not use the loan_test.csv for finding the best k, however, you can split your train_loan.csv into train and test to find the best k.

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)
#OUTPUT:
Train set: (276, 8) (276,)
Test set: (70, 8) (70,)

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
Ks=12
mean_acc = np.zeros((Ks-1))
std_acc=np.zeros((Ks-1))
for n in range (1, Ks):
    neigh = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1]=metrics.accuracy_score(y_test,yhat)
    std_acc[n-1]=np.std(yhat==y_test)/(np.sqrt(yhat.shape[0]))
mean_acc
#OUTPUT:
array([0.64285714, 0.58571429, 0.74285714, 0.7       , 0.74285714,
       0.71428571, 0.8       , 0.75714286, 0.74285714, 0.68571429,
       0.71428571])

print("The best accuracy was with", mean_acc.max(), "with K=", mean_acc.argmax()+1)
#The best accuracy was with 0.8 with K= 7

plt.plot(range(1,Ks), mean_acc, 'g')
plt.fill_between(range(1,Ks), mean_acc-1*std_acc, mean_acc +1 * std_acc, alpha=0.10)
plt.fill_between(range(1,Ks), mean_acc-3*std_acc, mean_acc +3 * std_acc, alpha=0.10, color="green")
plt.legend(('Accuracy', '+/- 1xstd','+/- 3xstd'))
plt.ylabel('Accuracy')
plt.xlabel('Number of Neighbors (K)')
plt.tight_layout()
plt.show()
#OUTPUT:
##GRAPH##

K=7
neigh=KNeighborsClassifier(n_neighbors=K).fit(X_train, y_train)
neigh
KNeighborsClassifier(n_neighbors=7)
yhat=neigh.predict(X_test)
yhat[0:5]
#OUTPUT:
array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],
      dtype=object)

yhat
print("Train set accuracy: ", metrics.accuracy_score(y_train,neigh.predict(X_train)))
print("Test set accuracy: ", metrics.accuracy_score(y_test,yhat))
#OUTPUT:
Train set accuracy:  0.8043478260869565
Test set accuracy:  0.8






